{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sps\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_proj_simplex(v, s=1):\n",
    "    n, = v.shape  # will raise ValueError if v is not 1-D\n",
    "    # check if we are already on the simplex\n",
    "    if v.sum() == s and np.alltrue(v >= 0):\n",
    "        # best projection: itself!\n",
    "        return v\n",
    "    # get the array of cumulative sums of a sorted (decreasing) copy of v\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u)\n",
    "    # get the number of > 0 components of the optimal solution\n",
    "    rho = np.nonzero(u * np.arange(1, n+1) > (cssv - s))[0][-1]\n",
    "    # compute the Lagrange multiplier associated to the simplex constraint\n",
    "    theta = (cssv[rho] - s) / (rho + 1.0)\n",
    "    # compute the projection by thresholding v using theta\n",
    "    w = (v - theta).clip(min=0)\n",
    "    return w\n",
    "\n",
    "\n",
    "def ternary_search(func, left, right, precision):\n",
    "    # finds argmax of convex function f\n",
    "    # on the segment [left; right] with given precision\n",
    "    if abs(right - left) < precision:\n",
    "        return left\n",
    "\n",
    "    left_third = (2*left + right)/3\n",
    "    right_third = (left + 2*right)/3\n",
    "    if func(left_third) == func(right_third):\n",
    "        return ternary_search(func, left_third, right_third, precision) \n",
    "    if func(left_third) < func(right_third):\n",
    "        return ternary_search(func, left_third, right, precision) \n",
    "    else:\n",
    "        return ternary_search(func, left, right_third, precision)\n",
    "\n",
    "\n",
    "def line_search(f, precision=1e-7, estimate=0):\n",
    "    # finds argmax of convex function f\n",
    "    # on the line with given precision\n",
    "    curr = estimate\n",
    "    delta = 1\n",
    "    while f(curr + delta) > f(curr):\n",
    "        curr = curr + delta\n",
    "        delta *= 2\n",
    "    curr_left = estimate\n",
    "    delta_left = 1\n",
    "    while f(curr_left - delta_left) > f(curr_left):\n",
    "        curr_left = curr_left - delta_left\n",
    "        delta_left *= 2\n",
    "    return ternary_search(f, curr_left - delta_left, curr + delta, precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient descent method\n",
    "\n",
    "def proj_grad_descent(x0, precision, max_iters):\n",
    "    cur_x = x0\n",
    "    previous_step_size = 1\n",
    "    iters = 0\n",
    "    while previous_step_size > precision and iters < max_iters:\n",
    "        prev_x = cur_x\n",
    "        grad = df(prev_x)\n",
    "        \n",
    "        def func(alpha):\n",
    "            return f(euclidean_proj_simplex(prev_x + alpha * grad))\n",
    "        alpha = line_search(func)\n",
    "\n",
    "        cur_x = euclidean_proj_simplex(prev_x + alpha * grad)\n",
    "        previous_step_size = np.linalg.norm(cur_x - prev_x)\n",
    "        iters += 1\n",
    "        \n",
    "    np.set_printoptions(precision=4)\n",
    "    print(\"The local maximum of proj grad occurs at\", cur_x)\n",
    "    print(\"Number of gradient iterations: \", iters)\n",
    "    return cur_x\n",
    "\n",
    "\n",
    "# Quasi-Newton method\n",
    "\n",
    "def proj_quasi_newton_method (x0, precision, max_iters):\n",
    "    # DFP algorithm\n",
    "    cur_x = x0\n",
    "    previous_step_size = 1\n",
    "    iters = 0\n",
    "    H = np.eye(np.size(x0))\n",
    "    alpha = 1\n",
    "    while previous_step_size > precision and iters < max_iters:\n",
    "        prev_x = cur_x\n",
    "        h = -H @ df(prev_x)\n",
    "        \n",
    "        def func(alpha):\n",
    "            return f(euclidean_proj_simplex(prev_x + alpha * h))\n",
    "        \n",
    "        alpha = line_search(func)\n",
    "        \n",
    "        cur_x = euclidean_proj_simplex(prev_x + alpha * h)\n",
    "        s = np.atleast_2d(cur_x - prev_x).T\n",
    "        y = np.atleast_2d(df(cur_x) - df(prev_x)).T\n",
    "        \n",
    "        H = H - (H @ y @ y.T @ H) / (y.T @ H @ y) + (s @ s.T) / (y.T @ s)\n",
    "        previous_step_size = np.linalg.norm(cur_x - prev_x) \n",
    "        iters += 1\n",
    "        \n",
    "    np.set_printoptions(precision=4)\n",
    "    print(\"The local maximum of quasi newton occurs at\", cur_x)\n",
    "    print(\"Number of quasi-newton iterations: \", iters)\n",
    "    return cur_x\n",
    "\n",
    "\n",
    "# Newton method \n",
    "\n",
    "def proj_newton_method (x0, precision, max_iters):\n",
    "    cur_x = x0\n",
    "    previous_step_size = 1\n",
    "    iters = 0\n",
    "    while previous_step_size > precision and iters < max_iters:\n",
    "        prev_x = cur_x\n",
    "        h = - np.linalg.inv(ddf(prev_x)) @ df(prev_x)\n",
    "        def func(alpha):\n",
    "            return f(euclidean_proj_simplex(prev_x + alpha * h))\n",
    "        \n",
    "        alpha = line_search(func)\n",
    "        cur_x = euclidean_proj_simplex(prev_x + alpha * h)\n",
    "        previous_step_size = np.linalg.norm(cur_x - prev_x) \n",
    "        iters += 1\n",
    "        \n",
    "    np.set_printoptions(precision=4)\n",
    "    print(\"The local maximum of newton occurs at\", cur_x)\n",
    "    print(\"Number of newton iterations: \", iters)\n",
    "    return cur_x\n",
    "\n",
    "\n",
    "# Interior point method\n",
    "\n",
    "def interior_point_method(x0, t0, alpha, precision, max_iters):   \n",
    "    n = x0.size\n",
    "    A = np.atleast_2d(np.ones(n))\n",
    "    b = np.ones(1)\n",
    "    cur_x = x0\n",
    "    t = t0\n",
    "    \n",
    "    def phi(x, t):\n",
    "        if np.min(x) <= 0:\n",
    "            return -np.inf\n",
    "        return f(x) + t * np.sum(np.log(x))\n",
    "    \n",
    "    def phi_grad(x, t):\n",
    "        return df(x) + t/x\n",
    "    \n",
    "    def phi_hess(x, t):\n",
    "        return ddf(x) - t * np.diag(1/(x**2))\n",
    "    \n",
    "    def newton_equality_feasible(x0, A, b, t):\n",
    "        # solves maximization problem for phi(x, t) with constraints Ax = b \n",
    "        cur_x = x0\n",
    "        m = A.shape[0]\n",
    "        n = A.shape[1]\n",
    "        while True:\n",
    "            newton_matrix = np.bmat([[-phi_hess(cur_x, t), A.T], [A, np.zeros((m, m))]])\n",
    "            rhs = np.atleast_2d(np.hstack([phi_grad(cur_x, t), np.zeros(m)])).T\n",
    "            w = np.linalg.solve(newton_matrix, rhs)\n",
    "            h = w[:n]\n",
    "            if np.abs(h.T @ phi_hess(cur_x, t) @ h) < precision:\n",
    "                break\n",
    "            \n",
    "            h = h.reshape(n)\n",
    "            \n",
    "            def func(alpha):\n",
    "                return phi(cur_x + alpha * h, t)\n",
    "            \n",
    "            alpha = line_search(func)\n",
    "            cur_x = cur_x + alpha * h\n",
    "        return cur_x\n",
    "   \n",
    "    while True:\n",
    "        cur_x = newton_equality_feasible(cur_x, A, b, t)\n",
    "        if n * t < precision:\n",
    "            break\n",
    "        t *= alpha\n",
    "    print(\"The local maximum of interior point method occurs at\", cur_x)\n",
    "    return cur_x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "n = 5\n",
    "m = 5\n",
    "\n",
    "P = np.random.rand(n, m) \n",
    "P /= P.sum(axis=1)[:,None]\n",
    "P = P.T\n",
    "c = (P * np.log2(P)).sum(axis=0)\n",
    "\n",
    "def f(x):\n",
    "    array = (P @ x) * np.log2(P @ x)\n",
    "    return c @ x - array.sum() \n",
    "\n",
    "def df(x):\n",
    "    k = P.shape[0]\n",
    "    array = np.array([P[i] * (np.log2(P[i] @ x) + 1/np.log(2)) for i in range(k)])\n",
    "    return c - array.sum(axis=0)\n",
    "\n",
    "def ddf(x):\n",
    "    k = P.shape[0]\n",
    "    t = P @ x\n",
    "    array = np.array([np.atleast_2d(P[i]).T @ np.atleast_2d(P[i]) for i in range(k)])\n",
    "    result = - np.array([array[i] / (np.log(2) * t[i]) for i in range(k)]).sum(axis=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting point: [ 0.2923  0.0943  0.2133  0.2076  0.1925]\n",
      "The local maximum of proj grad occurs at [ 0.0117  0.      0.4703  0.      0.518 ]\n",
      "Number of gradient iterations:  29\n",
      "max proj grad capacity: 0.246013234784 \n",
      "\n",
      "The local maximum of quasi newton occurs at [  2.3636e-01   1.3711e-09   2.1548e-01   1.4127e-01   4.0689e-01]\n",
      "Number of quasi-newton iterations:  5\n",
      "max proj quasi newton capacity: 0.223841316672 \n",
      "\n",
      "The local maximum of newton occurs at [ 0.4846  0.      0.1421  0.      0.3733]\n",
      "Number of newton iterations:  5\n",
      "max proj newton capacity: 0.215658548458 \n",
      "\n",
      "The local maximum of interior point method occurs at [  1.1978e-02   5.5742e-07   4.7010e-01   8.1303e-07   5.1792e-01]\n",
      "max interior point method capacity: 0.24601302442\n"
     ]
    }
   ],
   "source": [
    "x0 = np.random.rand(5)\n",
    "x0 /= x0.sum()\n",
    "precision = 10**-6\n",
    "iters = 10**3\n",
    "\n",
    "print('Starting point:', x0)\n",
    "\n",
    "x1 = proj_grad_descent(x0, precision, iters)\n",
    "print(\"max proj grad capacity:\", f(x1), '\\n')\n",
    "x2 = proj_quasi_newton_method (x0,  precision, iters)\n",
    "print(\"max proj quasi newton capacity:\", f(x2), '\\n')\n",
    "x3 = proj_newton_method (x0, precision, iters)\n",
    "print(\"max proj newton capacity:\", f(x3), '\\n')\n",
    "x4 = interior_point_method(x0, 1, 0.1, precision, iters)\n",
    "print(\"max interior point method capacity:\", f(x4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
