{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sps\n",
    "import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent(x0, alpha, precision, max_iters):\n",
    "    cur_x = x0\n",
    "    previous_step_size = 1\n",
    "    iters = 0\n",
    "    while previous_step_size > precision and iters < max_iters:\n",
    "        prev_x = cur_x\n",
    "        cur_x = cur_x + alpha * df(prev_x)\n",
    "        previous_step_size = np.linalg.norm(cur_x - prev_x) \n",
    "        iters += 1\n",
    "    \n",
    "    print(\"The local maximum of grad occurs at\", cur_x)\n",
    "    return cur_x\n",
    "    \n",
    "def proj_grad_descent(x0, alpha, precision, max_iters):\n",
    "    cur_x = x0\n",
    "    previous_step_size = 1\n",
    "    iters = 0\n",
    "    while previous_step_size > precision and iters < max_iters:\n",
    "        prev_x = cur_x\n",
    "        cur_x = euclidean_proj_simplex(prev_x + alpha * df(prev_x))\n",
    "        previous_step_size = np.linalg.norm(cur_x - prev_x)\n",
    "        iters += 1\n",
    "        \n",
    "    print(\"The local maximum of proj grad occurs at\", cur_x)\n",
    "    return cur_x\n",
    "    \n",
    "def euclidean_proj_simplex(v, s=1):\n",
    "    n, = v.shape  # will raise ValueError if v is not 1-D\n",
    "    # check if we are already on the simplex\n",
    "    if v.sum() == s and np.alltrue(v >= 0):\n",
    "        # best projection: itself!\n",
    "        return v\n",
    "    # get the array of cumulative sums of a sorted (decreasing) copy of v\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u)\n",
    "    # get the number of > 0 components of the optimal solution\n",
    "    rho = np.nonzero(u * np.arange(1, n+1) > (cssv - s))[0][-1]\n",
    "    # compute the Lagrange multiplier associated to the simplex constraint\n",
    "    theta = (cssv[rho] - s) / (rho + 1.0)\n",
    "    # compute the projection by thresholding v using theta\n",
    "    w = (v - theta).clip(min=0)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_matrix = np.random.rand(5,5) \n",
    "t_matrix /= t_matrix.sum(axis=1)[:,None]\n",
    "\n",
    "c_matrix = (t_matrix * np.log2(t_matrix)).sum(axis=-1)\n",
    "\n",
    "f = lambda x: c_matrix.T @ x - ((t_matrix @ x) * np.log2(t_matrix @ x)).sum(axis=-1)\n",
    "\n",
    "df = lambda x: c_matrix.T - (t_matrix * (np.log2(t_matrix @ x) + 1)).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34469945 0.15227411 0.07701194 0.35510108 0.07091341]\n",
      "The local maximum of proj grad occurs at [0.34470022 0.15227266 0.07701056 0.35510386 0.0709127 ]\n",
      "max proj grad capacity: 0.32486706971757995\n"
     ]
    }
   ],
   "source": [
    "x0 = np.random.rand(5) * 5\n",
    "x0 /= x0.sum()\n",
    "print(x0)\n",
    "alpha = 0.00001\n",
    "precision = 10**-2\n",
    "iters = 10**5\n",
    "\n",
    "# x = grad_descent(x0, alpha, precision, iters)\n",
    "# print(\"max grad capacity:\", f(x))\n",
    "x = proj_grad_descent(x0, alpha, precision, iters)\n",
    "print(\"max proj grad capacity:\", f(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in log2\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(np.log2(-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
